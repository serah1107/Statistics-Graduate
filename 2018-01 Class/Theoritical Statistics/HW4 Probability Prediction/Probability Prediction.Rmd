---
title: "Homework#4"
author: "Hye Yun Oh"
date: "2018년 4월 3일"
output: html_document
---

```{r}

## (1)

library(growthmodels)
library(tidyverse)
library(jmuOutlier)


###데이터 전처리 

oring<-read.csv("C:\\Users\\user\\Desktop\\O-ring data.csv",header=TRUE)
head(oring)

####변수명지정

names(oring)<-c("m","n","y","x")
head(oring)


####NA값 생략

oring<-oring%>%filter(oring$y!='*')

### glm 

mylogit<- glm(y~x,data=oring,family=binomial(link = "logit"))
summary(mylogit)


### mle (logit) 

attach(oring)

f1_logit<-function(data,c) {  

	x<-data$x
	x<-as.numeric(x)

 	y<-data$y
	y<-as.numeric(y)

        p<-plogis(c[1]+c[2]*x) # malfunctioning probability vector
        p<-as.numeric(p) 

        -sum( log(  dbinom(y,6,p) ,exp(1))  ) # expression
          }

result1_logit <- optim(rep(0,2), f1_logit, data=oring, method= "BFGS", hessian=T)   
result1_logit  

### AIC (logit) 

b1_logit<-result1_logit$par
AIC_logit<-2*result1_logit$value+2*length(b1_logit)
AIC_logit


### glm (probit) 

myprobit<- glm(y~x,data=oring,family=binomial(link = "probit"))
summary(myprobit)

### mle (probit) 

attach(oring)

f1_probit<-function(data,c) {  

	x<-data$x
	x<-as.numeric(x)

 	y<-data$y
	y<-as.numeric(y)

        p<-pnorm(c[1]+c[2]*x) # malfunctioning probability vector
        p<-as.numeric(p) 

        -sum( log(  dbinom(y,6,p) ,exp(1))  ) # expression
          }

result1_probit <- optim(rep(0,2), f1_probit, data=oring, method= "BFGS", hessian=T)        
result1_probit

### AIC (probit) 

b1_probit<-result1_probit$par
AIC_probit<-2*result1_probit$value+2*length(b1_probit)
AIC_probit

### mle (gompit) 

attach(oring)

pgompertz<-function(z){

    1-exp(-exp(z))
}

f1_gompit<-function(data,c) {  

	x<-data$x
	x<-as.numeric(x)

 	y<-data$y
	y<-as.numeric(y)

        p<-pgompertz(c[1]+c[2]*x) # malfunctioning probability vector
        p<-as.numeric(p) 

        -sum( log(  dbinom(y,6,p) ,exp(1))  ) # expression
          }

result1_gompit <- optim(rep(0,2), f1_gompit, data=oring, method= "BFGS", hessian=T)        
result1_gompit 

###AIC (gompit) 

b1_gompit<-result1_gompit$par
AIC_gompit<-2*result1_gompit$value+2*length(b1_gompit)
AIC_gompit

## Adequate AIC (a) 

rr0<-c('linkftn','-2lntheta', '2p', 'AIC')
rr1<-c('logit',2*result1_logit$value,2*length(b1_logit),AIC_logit)
rr2<-c('probit',2*result1_probit$value,2*length(b1_probit),AIC_probit)
rr3<-c('gompit',2*result1_gompit$value,2*length(b1_gompit),AIC_gompit)  #gompit이 AIC가 제일 작으므로 채택 

AICtable1<-rbind(rr0,rr1,rr2,rr3)
AICtable1

## Gompit model (b) 

###H0

gompit_h0<-function(data,c) {  

	x<-data$x
	x<-as.numeric(x)

 	y<-data$y
	y<-as.numeric(y)

        p<-pgompertz(c[1]) # malfunctioning probability vector
        p<-as.numeric(p) 

        -sum( log(  dbinom(y,6,p) ,exp(1))  ) # expression
          }

opt_gompit_h0<- optim(rep(0,1),gompit_h0, data=oring, method= "BFGS", hessian=T)        
opt_gompit_h0

b_gompit_h0<-opt_gompit_h0$par
AIC_gompit_H0<-2*opt_gompit_h0$value+2*length(b_gompit_h0)
AIC_gompit_H0

###H1

gompit_h1<-function(data,c) {  

	x<-data$x
	x<-as.numeric(x)

 	y<-data$y
	y<-as.numeric(y)

        p<-pgompertz(c[1]+c[2]*x) # malfunctioning probability vector
        p<-as.numeric(p) 

        -sum( log(  dbinom(y,6,p) ,exp(1))  ) # expression
          }
opt_gompit_h1<- optim(rep(0,2), gompit_h1, data=oring, method= "BFGS", hessian=T)        
opt_gompit_h1

b_gompit_h1<-opt_gompit_h1$par
AIC_gompit_H1<-2*opt_gompit_h1$value+2*length(b_gompit_h1)
AIC_gompit_H1

## Adequate AIC (b)

rrr0<-c('model','-2lntheta', '2p', 'AIC')
rrr1<-c('HO',2*opt_gompit_h0$value,2*length(b_gompit_h0),AIC_gompit_H0) #H0 채택  
rrr2<-c('H1',2*opt_gompit_h1$value,2*length(b_gompit_h1),AIC_gompit_H1)   

gompittable<-rbind(rrr0,rrr1,rrr2)
gompittable

## standard errors & CI (c) 

estimates_gom <- opt_gompit_h0$par     # Parameters estimates
se_gom <- sqrt(diag(solve(opt_gompit_h0$hessian))) # Standard errors of the estimates
se_gom

alpha_interval_gom<-c(estimates_gom[1]-1.96*se_gom[1],estimates_gom[1]+1.96*se_gom[1])
alpha_interval_gom

##standard errors & CI (d) 

##H0

P_H0<-pgompertz(estimates_gom[1])
P_H0
N_HO<-6*pgompertz(estimates_gom[1])
N_HO


####앞에서 H0일 때, AIC가 더 작아 H0를 채택하여, x값에 관계없이 고장확률과 고장개수가 같은 것으로 나왔습니다. 
####따라서 구한 결과, 온도에 관계없이 평균적으로 고장개수는 2개 정도이며, 고장확률은 0.4 정도임을 알 수 있었습니다. 


```
```{r}
##(2)  


library(ggplot2)
library(tidyverse)
library(jmuOutlier)


###데이터 전처리

leukemia<-read.csv("C:\\Users\\user\\Desktop\\leukemia data.csv",header=TRUE)
head(leukemia)


####변수명지정

names(leukemia)<-c("y","x")
head(leukemia)


####로그 취하기

leukemia<-as.tibble(leukemia) %>% filter(leukemia$x!='NA')%>% mutate(lny=log(y,exp(1)),lnx=log(x,exp(1)))
head(leukemia)


##산점도 (a) 

attach(leukemia)
ggplot(leukemia,aes(lnx,lny))+geom_point()

##LSE (a) 

lse<-lm(lny~lnx,leukemia)
e<-residuals(lse)

## Normal QQplot

plot(lse)

## Gompertz QQplot (a) 

e1<-sort(e,decreasing=F)
e1<-as.tibble(e1)%>% mutate(i=1:length(e1),pr=i/(length(e1)+1),gprime=log(-log((1-pr),exp(1)),exp(1)))
ggplot(e1,aes(gprime,value))+geom_point()+ggtitle("Gompertz Q-Q plot")+geom_smooth(method="lm")

####오차의 분포는 gompertz를 따른다

## mle (lognorm) (b) 


f2_lognorm<-function(data,c2) {  

	lnx<-data$lnx
	lnx<-as.numeric(lnx)

 	lny<-data$lny
	lny<-as.numeric(lny)

	e<-as.numeric(e)
 
        -sum( log( dnorm(lny,c2[1]+c2[2]*lnx,c2[3]) ,exp(1))  ) # expression
          }

result2_lognorm <- optim(rep(1,3), f2_lognorm, data=leukemia, method= "BFGS", hessian=T)        
result2_lognorm


## AIC(lognorm) (b) 

b2_lognorm<-result2_lognorm$par
AIC_lognorm<-2*result2_lognorm$value+2*length(b2_lognorm)
AIC_lognorm


## mle (loggompertz) (c) 


### sum((e+0.57721)^2)/16 = 1.778669 (e분산)

pgompertz<-function(z){

    1-exp(-exp(z))
    
}

dgompertz<-function(z, mean, sigma){

    exp((z-mean)/sigma-exp((z-mean)/sigma))*(1/sigma)
   
}

f2_gompertz<-function(data,c2) {  

	lnx<-data$lnx
	lnx<-as.numeric(lnx)

 	lny<-data$lny
	lny<-as.numeric(lny)

        e<-as.numeric(e)

 
        -sum( log( dgompertz(lny,c2[1]+c2[2]*lnx-0.57721*c2[3],c2[3]*1.778669^(1/2)),exp(1))) # expression
          }

result2_gompertz<- optim(c(0,0,50), f2_gompertz, data=leukemia, method= "BFGS", hessian=T)        
result2_gompertz


## AIC(loggompertz) (c) 

b2_gompertz<-result2_gompertz$par
AIC_gompertz<-2*result2_gompertz$value+2*length(b2_gompertz)
AIC_gompertz  

## standard errors & CI (d) 

estimates2_gom<- result2_gompertz$par     # Parameters estimates
se2_gom <- sqrt(diag(solve(result2_gompertz$hessian))) # Standard errors of the estimates
se2_gom

alpha_interval2<-c(estimates2_gom[1]-1.96*se2_gom[1],estimates2_gom[1]+1.96*se2_gom[1])
alpha_interval2
beta_interval2<-c(estimates2_gom[2]-1.96*se2_gom[2],estimates2_gom[2]+1.96*se2_gom[2])
beta_interval2
resi_interval2<-c(estimates2_gom[3]-1.96*se2_gom[3],estimates2_gom[3]+1.96*se2_gom[3])
resi_interval2


## Adequate AIC (e) 


r1<-c('lognormal',2*result2_lognorm$value,2*length(b2_lognorm),AIC_lognorm)      #log normal 채택
r2<-c('logGompertz',2*result2_gompertz$value,2*length(b2_gompertz),AIC_gompertz)

AICtable2<-rbind(r1,r2)
AICtable2



##  Survival probability (f)


t<-c(52,104,260)
xxx<-20
sigmahat<-sqrt(var(lny))
alphahat_norm<-result2_lognorm$par[1]
betahat_norm<-result2_lognorm$par[2]

alphahat_gom<-result2_gompertz$par[1]
betahat_gom<-result2_gompertz$par[2]


prob_1_norm<-1-pnorm((log(t[1],exp(1))-alphahat_norm-betahat_norm*log(xxx,exp(1)))/ sigmahat)
prob_2_norm<-1-pnorm((log(t[2],exp(1))-alphahat_norm-betahat_norm*log(xxx,exp(1)))/ sigmahat)
prob_3_norm<-1-pnorm((log(t[3],exp(1))-alphahat_norm-betahat_norm*log(xxx,exp(1)))/sigmahat)


prob_1_gom<-1-pgompertz((log(t[1],exp(1))-alphahat_gom-betahat_gom*log(xxx,exp(1)))/sigmahat)
prob_2_gom<-1-pgompertz((log(t[2],exp(1))-alphahat_gom-betahat_gom*log(xxx,exp(1)))/sigmahat)
prob_3_gom<-1-pgompertz((log(t[3],exp(1))-alphahat_gom-betahat_gom*log(xxx,exp(1)))/sigmahat)


log_normal<-c(prob_1_norm,prob_2_norm,prob_3_norm)
log_gompertz<-c(prob_1_gom,prob_2_gom,prob_3_gom)


Survivaltable<-cbind(t,log_normal,log_gompertz)
Survivaltable

####log gompertz의 경우가 생존 확률이 조금 더 크게 나왔습니다. 생존확률이 시간이 지남에 따라 당연하게 커지는 것을 알 수 있었습니다. log normal의 경우는 r 패키지에 함수가 내장되어 있어 구하기 편리했으나, gompertz의 경우엔 내장되어 있으나, alpha beta, t를 입력해야 하는 번거로움이 있어 사용하지 못했습니다.
####생존확률이 보통 gompertz를 따르기 때문에, 결과값이 log normal을 따른다고 나와서 조금 의아했습니다. 그러나 aic가 근소하게 차이났기 때문에 log gompertz를 따른다고 보아도 무방할 것 같습니다. 
####gompertz distribution이 normal distribution에 비해 생존 확률을 더 잘 나타내는 것 같습니다. 

```
```{r}
#(3)  

library(ggplot2)
library(tidyverse)
library(jmuOutlier)

##데이터 전처리 

weibull_table1<-read.csv("C:\\Users\\user\\Desktop\\weibull.csv",header=T)
weibull_table2<-read.csv("C:\\Users\\user\\Desktop\\weibull2.csv",header=T)
head(weibull_table1)
head(weibull_table2)

##histogram (a)
ggplot(weibull_table1, aes(x=x,y = expected)) +geom_bar(stat = "identity")
ggplot(weibull_table1, aes(x=x,y = observed)) +geom_bar(stat = "identity")
ggplot(weibull_table1, aes(x=x,y = normal)) +geom_bar(stat = "identity")  

ggplot(weibull_table2, aes(x=x,y = expected)) +geom_bar(stat = "identity")
ggplot(weibull_table2, aes(x=x,y = observed)) +geom_bar(stat = "identity")
ggplot(weibull_table2, aes(x=x,y = pearson)) +geom_bar(stat = "identity")

###weibull분포가 적합하다. 



## Weibull QQplot (b) & 모수추정


weibull_table1<-weibull_table1%>% mutate(i=1:length(weibull_table1$num),pr=i/(length(weibull_table1$num)+1),gprime=log(-log((1-pr),exp(1)),exp(1)))
weibull_table2<-weibull_table2%>% mutate(i=1:length(weibull_table2$x),pr=i/(length(weibull_table2$x)+1),gprime=log(-log((1-pr),exp(1)),exp(1)))

ggplot(weibull_table1,aes(gprime,log(x-25,exp(1))))+geom_point()+ggtitle("Weibull Q-Q plot1")+geom_smooth(method="lm") #a=25
ggplot(weibull_table2,aes(gprime,log(x-0.5,exp(1))))+geom_point()+ggtitle("Weibull Q-Q plot1")+geom_smooth(method="lm")#a=0.5

a1<-25
a2<-0.5

myweibull1<- lm(log(weibull_table1$x-25,exp(1))~gprime,weibull_table1)
summary(myweibull1)

mu1<-as.numeric(myweibull1$coefficients[1])
sigma1<-as.numeric(myweibull1$coefficients[2])
b1<-exp(mu1)
alpha1<-1/sigma1

myweibull2<- lm(log(weibull_table2$observed-0.5,exp(1))~gprime,weibull_table2)
summary(myweibull2)

mu2<-as.numeric(myweibull2$coefficients[1])
sigma2<-as.numeric(myweibull2$coefficients[2])
b2<-exp(mu2)
alpha2<-1/sigma2

mosu_weibull1<-c(25,b1,alpha1)
mosu_weibull1
mosu_weibull2<-c(0.5,b2,alpha2)
mosu_weibull2


## MLE & 모수추정 (구간=2)

largeF<-function(x,a,b,alpha){

1-exp(-((x-a)/b)^alpha)
}

smallf<-function(x,a,b,alpha){

(1/b)*((x-a)/b)^(alpha-1)*exp(-((x-a)/b)^alpha)
}

pi<-function(x,i,a,b,alpha,n){

(-exp(-((x[i]-a)/b)^alpha)+exp(-((x[i-1]-a)/b)^alpha)) *n[i]

}

### 데이터 정리

n1<-rep(0,length(weibull_table1$x))

for( i in 2:length(weibull_table1$x) ){
n1[i]<-weibull_table1$x[i-1]+weibull_table1$x[i]}

n1


n2<-rep(0,length(weibull_table2$x))

for( i in 2:length(weibull_table2$x)){
n2[i]<-weibull_table2$x[i-1]+weibull_table2$x[i]}

n2

weibull_table1<-as.tibble(weibull_table1)%>%mutate(n1=n1)
weibull_table2<-as.tibble(weibull_table2)%>%mutate(n2=n2)


### mle weibull

f3_weibull1<-function(data,c2) {  

       x<-data$x
       i<-2:length(data$x)

        -sum(log(pi(x,i,c2[1],c2[2],c2[3],n1)))# expression

          }

result3_weibull1 <- optim(rep(20,3), f3_weibull1, data=weibull_table1, method= "BFGS", hessian=T)        
result3_weibull1

f3_weibull2<-function(data,c2) {  

       x<-data$x
       i<-2:length(data$x)

        -sum(log(pi(x,i,c2[1],c2[2],c2[3],n2)))# expression

          }

result3_weibull2<- optim(c(0,10,1), f3_weibull2, data=weibull_table2, method= "BFGS", hessian=T)        
result3_weibull2


##standard errors & CI (d) 

estimates_weibull1 <- result3_weibull1$par     # Parameters estimates
estimates_weibull2 <- result3_weibull2$par    # Parameters estimates
se_weibull1 <- sqrt(diag(solve(result3_weibull1$hessian))) # Standard errors of the estimates
se_weibull2 <- sqrt(diag(solve(result3_weibull2$hessian))) # Standard errors of the estimates

a_interval_weibull1<-c(estimates_weibull1[1]-1.96*se_weibull1[1],estimates_weibull1[1]+1.96*se_weibull1[1])
a_interval_weibull2<-c(estimates_weibull2[1]-1.96*se_weibull2[1],estimates_weibull2[1]+1.96*se_weibull2[1])

a_interval_weibull1
a_interval_weibull2

b_interval_weibull1<-c(estimates_weibull1[2]-1.96*se_weibull1[2],estimates_weibull1[2]+1.96*se_weibull1[2])
b_interval_weibull2<-c(estimates_weibull2[2]-1.96*se_weibull2[2],estimates_weibull2[2]+1.96*se_weibull2[2])

b_interval_weibull1
b_interval_weibull2

alpha_interval_weibull1<-c(estimates_weibull1[3]-1.96*se_weibull1[3],estimates_weibull1[3]+1.96*se_weibull1[3])
alpha_interval_weibull2<-c(estimates_weibull2[3]-1.96*se_weibull2[3],estimates_weibull2[3]+1.96*se_weibull2[3])

alpha_interval_weibull1
alpha_interval_weibull2


```