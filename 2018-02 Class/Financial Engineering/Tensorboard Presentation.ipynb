{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#Import packages\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import urllib\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a graph session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Set model parameters\n",
    "with tf.name_scope(\"parameters\"):\n",
    "    batch_size = 128\n",
    "    data_dir = 'temp'\n",
    "    output_every = 50\n",
    "    epochs = 200\n",
    "    eval_every = 500\n",
    "    image_height = 32\n",
    "    image_width = 32\n",
    "    crop_height = 24\n",
    "    crop_width = 24\n",
    "    num_channels = 3\n",
    "    num_targets = 10\n",
    "    extract_folder = 'cifar-10-batches-bin'\n",
    "    \n",
    "    # Exponential Learning Rate Decay Params\n",
    "    learning_rate = 0.1\n",
    "    lr_decay = 0.1\n",
    "    num_gens_to_wait = 250.\n",
    "\n",
    "    # Extract model parameters\n",
    "    image_vec_length = image_height * image_width * num_channels\n",
    "    record_length = 1 + image_vec_length # ( + 1 for the 0-9 label)\n",
    "logs_path = '/tmp2/tensorflow_logs/example/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_dir = 'temp'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "cifar10_url = 'http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz'\n",
    "\n",
    "# Check if file exists, otherwise download it\n",
    "data_file = os.path.join(data_dir, 'cifar-10-binary.tar.gz')\n",
    "if os.path.isfile(data_file):\n",
    "    pass\n",
    "else:\n",
    "    # Download file\n",
    "    def progress(block_num, block_size, total_size):\n",
    "        progress_info = [cifar10_url, float(block_num * block_size) / float(total_size) * 100.0]\n",
    "        print('\\r Downloading {} - {:.2f}%'.format(*progress_info), end=\"\")\n",
    "    filepath, _ = urllib.request.urlretrieve(cifar10_url, data_file, progress)\n",
    "    # Extract file\n",
    "    tarfile.open(filepath, 'r:gz').extractall(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CIFAR reader\n",
    "def read_cifar_files(filename_queue, distort_images = True):\n",
    "    reader = tf.FixedLengthRecordReader(record_bytes=record_length)\n",
    "    key, record_string = reader.read(filename_queue)\n",
    "    record_bytes = tf.decode_raw(record_string, tf.uint8)\n",
    "    image_label = tf.cast(tf.slice(record_bytes, [0], [1]), tf.int32)\n",
    "  \n",
    "    # Extract image\n",
    "    image_extracted = tf.reshape(tf.slice(record_bytes, [1], [image_vec_length]),\n",
    "                                 [num_channels, image_height, image_width])\n",
    "    \n",
    "    # Reshape image\n",
    "    image_uint8image = tf.transpose(image_extracted, [1, 2, 0])\n",
    "    reshaped_image = tf.cast(image_uint8image, tf.float32)\n",
    "    # Randomly Crop image\n",
    "    final_image = tf.image.resize_image_with_crop_or_pad(reshaped_image, crop_width, crop_height)\n",
    "    \n",
    "    if distort_images:\n",
    "        # Randomly flip the image horizontally, change the brightness and contrast\n",
    "        final_image = tf.image.random_flip_left_right(final_image)\n",
    "        final_image = tf.image.random_brightness(final_image,max_delta=63)\n",
    "        final_image = tf.image.random_contrast(final_image,lower=0.2, upper=1.8)\n",
    "\n",
    "    # Normalize whitening\n",
    "    final_image = tf.image.per_image_standardization(final_image)\n",
    "    return final_image, image_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CIFAR image pipeline from reader\n",
    "def input_pipeline(batch_size, train_logical=True):\n",
    "    if train_logical:\n",
    "        files = [os.path.join(data_dir, extract_folder, 'data_batch_{}.bin'.format(i)) for i in range(1,6)]\n",
    "    else:\n",
    "        files = [os.path.join(data_dir, extract_folder, 'test_batch.bin')]\n",
    "    filename_queue = tf.train.string_input_producer(files)\n",
    "    image, label = read_cifar_files(filename_queue)\n",
    "    \n",
    "    # min_after_dequeue defines how big a buffer we will randomly sample\n",
    "    #   from -- bigger means better shuffling but slower start up and more\n",
    "    #   memory used.\n",
    "    # capacity must be larger than min_after_dequeue and the amount larger\n",
    "    #   determines the maximum we will prefetch.  Recommendation:\n",
    "    #   min_after_dequeue + (num_threads + a small safety margin) * batch_size\n",
    "    min_after_dequeue = 5000\n",
    "    capacity = min_after_dequeue + 3 * batch_size\n",
    "    example_batch, label_batch = tf.train.shuffle_batch([image, label],\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        capacity=capacity,\n",
    "                                                        min_after_dequeue=min_after_dequeue)\n",
    "\n",
    "    return example_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture, this will return logits from images\n",
    "def cifar_cnn_model(x, batch_size, train_logical=True):\n",
    "    \n",
    "    # 입력 이미지 \n",
    "    x_image = x \n",
    "    \n",
    "    # 첫번째 convolutional layer : 하나의 grayscale 이미지를 64개의 특징들(feature)으로 맵핑(maping)합니다.\n",
    "    with tf.variable_scope('layer1') as scope:\n",
    "        W_conv1 = tf.get_variable(\"W\", shape=[5, 5, 3, 64],initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b_conv1 = tf.Variable(tf.random_normal([64]))\n",
    "        h_conv1 = tf.nn.relu(tf.nn.conv2d(x_image, W_conv1, strides =[1, 1, 1, 1], padding= 'SAME') + b_conv1)\n",
    "        \n",
    "        # 첫번째 Pooling layer : Max Pooling\n",
    "        h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        \n",
    "    \n",
    "    #두번째 convolutional layer : 32개의 특징들(feature)을 64개의 특징들(feature)로 맵핑(maping)합니다. \n",
    "    with tf.variable_scope('layer2') as scope:\n",
    "        W_conv2 = tf.get_variable(\"W\", shape=[5, 5, 64, 64], initializer=tf.contrib.layers.xavier_initializer()) # Conv kernel is 5x5, across all prior 64 features and we create 64 more features \n",
    "        b_conv2 = tf.Variable(tf.random_normal([64]))\n",
    "        h_conv2 = tf.nn.relu(tf.nn.conv2d(h_pool1, W_conv2, strides=[1, 1, 1, 1], padding='SAME') + b_conv2) # Convolve filter across prior output with stride size of 1, then # ReLU element wise\n",
    "        \n",
    "        # 두번째 pooling layer : Max Pooling\n",
    "        h_pool2 = tf.nn.max_pool(h_conv2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        \n",
    "    # Reshape output into a single matrix for multiplication for the fully connected layers\n",
    "    reshaped_output = tf.reshape(h_pool2, [batch_size, -1])\n",
    "    reshaped_dim = reshaped_output.get_shape()[1].value\n",
    "    \n",
    "    # Fully Connected Layer : 1 - 2번의 downsampling 이후에, 우리의 32x32 이미지는 8x8x128 특징맵(feature map)이 됩니다. \n",
    "    # 이를 384개의 특징들로 맵핑(maping)합니다. \n",
    "    with tf.variable_scope('layer_full') as scope:\n",
    "        W_fc1 = tf.get_variable(\"W\", shape=[reshaped_dim, 384], initializer=tf.contrib.layers.xavier_initializer()) # Conv kernel is 5x5, across all prior 64 features and we create 64 more features \n",
    "        b_fc1 = tf.Variable(tf.random_normal([384]))\n",
    "        \n",
    "        # Reshape output into a single matrix for multiplication for the fully connected layers\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(reshaped_output, W_fc1) + b_fc1) \n",
    "\n",
    "        \n",
    "    with tf.variable_scope('layer_full2') as scope:\n",
    "        # Dropout - 모델의 복잡도를 컨트롤합니다. 특징들의 co-adaptation을 방지합니다. \n",
    "        h_fc1_drop = tf.nn.dropout(h_fc1, 0.8)\n",
    "        \n",
    "        # Fully Connected Layer 2 - 384개의 특징들(feature)을 10개의 클래스-airplane, automobile, bird...-로 맵핑(maping)합니다. \n",
    "        W_fc2 = tf.get_variable(\"W\", shape=[384, 10], initializer=tf.contrib.layers.xavier_initializer()) \n",
    "        b_fc2 = tf.Variable(tf.random_normal([10]))\n",
    "        \n",
    "        logits = tf.matmul(h_fc1_drop, W_fc2) + b_fc2 \n",
    "        y_pred = tf.nn.softmax(logits)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def cifar_loss(logits, targets):\n",
    "    \n",
    "    # Get rid of extra dimensions and cast targets into integers\n",
    "    targets = tf.squeeze(tf.cast(targets, tf.int32))\n",
    "    # Calculate cross entropy from logits and targets\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=targets)\n",
    "    # Take the average loss across batch size\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')\n",
    "    \n",
    "    tf.summary.scalar(\"loss\", cross_entropy_mean)\n",
    "    \n",
    "    return cross_entropy_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train step\n",
    "def train_step(loss_value, generation_num):\n",
    "    \n",
    "    # Our learning rate is an exponential decay after we wait a fair number of epochs\n",
    "    model_learning_rate = tf.train.exponential_decay(learning_rate, generation_num,\n",
    "                                                     num_gens_to_wait, lr_decay, staircase=True)\n",
    "    # Create optimizer\n",
    "    my_optimizer = tf.train.GradientDescentOptimizer(model_learning_rate)\n",
    "    # Initialize train step\n",
    "    train_step = my_optimizer.minimize(loss_value)\n",
    "    \n",
    "    return train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy function\n",
    "def accuracy_of_batch(logits, targets):\n",
    "    \n",
    "    # Make sure targets are integers and drop extra dimensions\n",
    "    targets = tf.squeeze(tf.cast(targets, tf.int32))\n",
    "    # Get predicted values by finding which logit is the greatest\n",
    "    batch_predictions = tf.cast(tf.argmax(logits, 1), tf.int32)\n",
    "    # Check if they are equal across the batch\n",
    "    predicted_correctly = tf.equal(batch_predictions, targets)\n",
    "    # Average the 1's and 0's (True's and False's) across the batch size\n",
    "    accuracy = tf.reduce_mean(tf.cast(predicted_correctly, tf.float32))\n",
    "\n",
    "    tf.summary.scalar(\"accuracy\", accuracy) \n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting/Transforming Data.\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "print('Getting/Transforming Data.')\n",
    "# Initialize the data pipeline\n",
    "images, targets = input_pipeline(batch_size, train_logical=True)\n",
    "# Get batch test images and targets from pipline\n",
    "test_images, test_targets = input_pipeline(batch_size, train_logical=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the CIFAR10 Model.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Declare Model\n",
    "print('Creating the CIFAR10 Model.')\n",
    "with tf.variable_scope('model_definition') as scope:\n",
    "    # Declare the training network model\n",
    "    model_output = cifar_cnn_model(images, batch_size)\n",
    "    # This is very important!!!  We must set the scope to REUSE the variables,\n",
    "    #  otherwise, when we set the test network model, it will create new random\n",
    "    #  variables.  Otherwise we get random evaluations on the test batches.\n",
    "    scope.reuse_variables()\n",
    "    test_output = cifar_cnn_model(test_images, batch_size)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Declare Loss Function.\n"
     ]
    }
   ],
   "source": [
    "# Declare loss function\n",
    "print('Declare Loss Function.')\n",
    "loss = cifar_loss(model_output, targets)\n",
    "\n",
    "# Create accuracy function\n",
    "accuracy = accuracy_of_batch(test_output, test_targets)\n",
    "\n",
    "# Summary\n",
    "summary = tf.summary.merge_all()\n",
    "\n",
    "# Create summary writer\n",
    "writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "global_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the Training Operation.\n",
      "Initializing the Variables.\n"
     ]
    }
   ],
   "source": [
    "# Create training operations\n",
    "print('Creating the Training Operation.')\n",
    "generation_num = tf.Variable(0, trainable=False)\n",
    "train_op = train_step(loss, generation_num)\n",
    "\n",
    "# Initialize Variables\n",
    "print('Initializing the Variables.')\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Thread(QueueRunnerThread-input_producer-input_producer/input_producer_EnqueueMany, started daemon 4836)>,\n",
       " <Thread(QueueRunnerThread-shuffle_batch/random_shuffle_queue-shuffle_batch/random_shuffle_queue_enqueue, started daemon 13268)>,\n",
       " <Thread(QueueRunnerThread-input_producer_1-input_producer_1/input_producer_1_EnqueueMany, started daemon 3828)>,\n",
       " <Thread(QueueRunnerThread-shuffle_batch_1/random_shuffle_queue-shuffle_batch_1/random_shuffle_queue_enqueue, started daemon 11228)>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize queue (This queue will feed into the model, so no placeholders necessary)\n",
    "tf.train.start_queue_runners(sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "50 epochs : Loss = 2.31892\n",
      "100 epochs : Loss = 2.19319\n",
      "150 epochs : Loss = 2.19093\n",
      "200 epochs : Loss = 2.14684\n",
      "Run the command line:\n",
      "--> tensorboard --logdir=/tmp/tensorflow_logs\n"
     ]
    }
   ],
   "source": [
    "# Train CIFAR Model\n",
    "print('Starting Training')\n",
    "train_loss = []\n",
    "test_accuracy = []\n",
    "for i in range(epochs):\n",
    "    s, _, loss_value = sess.run([summary,train_op, loss])\n",
    "    writer.add_summary(s, global_step=global_step)\n",
    "    global_step += 1\n",
    "    \n",
    "    if (i+1) % output_every == 0:\n",
    "        train_loss.append(loss_value)\n",
    "        output = '{} epochs : Loss = {:.5f}'.format((i+1), loss_value)\n",
    "        print(output)\n",
    "    \n",
    "    if (i+1) % eval_every == 0:\n",
    "        [temp_accuracy] = sess.run([accuracy])\n",
    "        test_accuracy.append(temp_accuracy)\n",
    "        acc_output = ' --- Test Accuracy = {:.2f}%.'.format(100.*temp_accuracy)\n",
    "        print(acc_output)\n",
    "        \n",
    "print(\"Run the command line:\\n\" \\\n",
    "          \"--> tensorboard --logdir=/tmp/tensorflow_logs\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
